{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "05i1iW9bgSWw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import tensorflow_datasets as tfds\n",
        "import json\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfu-r9cuhajP",
        "outputId": "da1c35b6-7c1b-4d57-d32c-a6999290969a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-07 17:56:40--  https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.200.128, 142.250.152.128, 142.250.128.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.200.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘sarcasm.json.1’\n",
            "\n",
            "\rsarcasm.json.1        0%[                    ]       0  --.-KB/s               \rsarcasm.json.1      100%[===================>]   5.38M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-02-07 17:56:40 (189 MB/s) - ‘sarcasm.json.1’ saved [5643545/5643545]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/sarcasm.json')\n",
        "raw_dataset = json.load(f)"
      ],
      "metadata": {
        "id": "xI_O35V5hdfd"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "labels = []\n",
        "for data in raw_dataset:\n",
        "  dataset.append(data['headline'])\n",
        "  labels.append(int(data['is_sarcastic']))  "
      ],
      "metadata": {
        "id": "-g4vENGHiMme"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_test_split(datset, lables, train_val_split_size, val_test_split_size):\n",
        "  train_val_split_size = int(len(dataset) * train_val_split_size)\n",
        "  val_test_split_size = int((len(dataset) - train_val_split_size) * val_test_split_size) \n",
        "\n",
        "  print(len(dataset))\n",
        "  print(train_val_split_size)\n",
        "  print(val_test_split_size)\n",
        "\n",
        "  train_dataset, val_test_dataset = dataset[:train_val_split_size], dataset[train_val_split_size:]\n",
        "  val_dataset, test_dataset = val_test_dataset[:val_test_split_size], val_test_dataset[val_test_split_size:]\n",
        "\n",
        "  train_labels, val_test_labels = labels[:train_val_split_size], labels[train_val_split_size:]\n",
        "  val_labels, test_labels = val_test_labels[:val_test_split_size], val_test_labels[val_test_split_size:]\n",
        "\n",
        "  return train_dataset, train_labels, val_dataset, val_labels, test_dataset, test_labels  "
      ],
      "metadata": {
        "id": "3kd84FWGiR69"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_set, train_labels, raw_validation_set, validation_labels, raw_test_set, test_labels = train_val_test_split(dataset, labels, 0.7, 0.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHyQZvPnjDGe",
        "outputId": "dfda8253-ea5b-4bd1-aa82-1af2ef54de28"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26709\n",
            "18696\n",
            "4807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(raw_train_set))\n",
        "print(len(train_labels))\n",
        "print(len(raw_validation_set))\n",
        "print(len(validation_labels))\n",
        "print(len(raw_test_set))\n",
        "print(len(test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKgMkl7YjECE",
        "outputId": "f90e547a-717a-46d5-e2a7-4868008dd67b"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18696\n",
            "18696\n",
            "4807\n",
            "4807\n",
            "3206\n",
            "3206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 5000\n",
        "MAX_SEQUENCE_LENGTH = 250"
      ],
      "metadata": {
        "id": "y1cjK2Mz1ylO"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using TextVectorization: A preprocessing layer which maps text features to integer sequences**"
      ],
      "metadata": {
        "id": "-K4ZdWnBAqiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = TextVectorization(max_tokens = VOCAB_SIZE, output_mode = 'int', output_sequence_length = MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "vectorize_layer.adapt(raw_train_set)"
      ],
      "metadata": {
        "id": "2Qz2BjBuoWp0"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(text, labels):\n",
        "  return vectorize_layer(text), labels"
      ],
      "metadata": {
        "id": "8iaFuf5trv7r"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorize_text(raw_train_set[0], labels[0])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9oEBKH9r5Rb",
        "outputId": "deb6ee51-b33a-43f7-f136-6b478d773829"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ 323    1  919 4405 2227   47  365   91 1901    6 2741    1    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(250,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = tf.data.Dataset.from_tensor_slices((raw_train_set, train_labels))\n",
        "\n",
        "#shuffling on validation or test is useless as there is only one forward pass to calcualte the accuracy score\n",
        "validation_set = tf.data.Dataset.from_tensor_slices((raw_validation_set, validation_labels)) \n",
        "test_set = tf.data.Dataset.from_tensor_slices((raw_test_set, test_labels))"
      ],
      "metadata": {
        "id": "4xa48a71yaBx"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_train_set = train_set.map(vectorize_text)\n",
        "final_validation_set = validation_set.map(vectorize_text)\n",
        "final_test_set = test_set.map(vectorize_text)"
      ],
      "metadata": {
        "id": "JaJzs2qVywMV"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_train_set = final_train_set.shuffle(1000).batch(64).prefetch(1)\n",
        "final_validation_set = final_validation_set.batch(64).prefetch(1)\n",
        "final_test_set = final_test_set.batch(64).prefetch(1)"
      ],
      "metadata": {
        "id": "kFxDvTJKtoxs"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "      layers.Embedding(VOCAB_SIZE + 1, 64),\n",
        "      layers.Conv1D(8, 5, padding=\"valid\", activation=\"relu\", strides=2),\n",
        "      layers.Dropout(0.5),\n",
        "      layers.GlobalMaxPooling1D(),\n",
        "      layers.Dense(1, activation = 'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "UO31aj6ZvvdM"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "savebest = tf.keras.callbacks.ModelCheckpoint(filepath = '/tmp/checkpoint',monitor = 'val_accuracy', save_best_only = True, save_weights_only = True)\n",
        "model.fit(final_train_set, epochs = 6, validation_data = final_validation_set, callbacks = [savebest])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okhkmswx1DQY",
        "outputId": "0b1e2dc2-cb52-4521-df5b-ea733f8ed2cd"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "293/293 [==============================] - 6s 18ms/step - loss: 0.5365 - accuracy: 0.7243 - val_loss: 0.4282 - val_accuracy: 0.8298\n",
            "Epoch 2/6\n",
            "293/293 [==============================] - 5s 16ms/step - loss: 0.3359 - accuracy: 0.8579 - val_loss: 0.3737 - val_accuracy: 0.8392\n",
            "Epoch 3/6\n",
            "293/293 [==============================] - 5s 17ms/step - loss: 0.2617 - accuracy: 0.8952 - val_loss: 0.3642 - val_accuracy: 0.8382\n",
            "Epoch 4/6\n",
            "293/293 [==============================] - 5s 16ms/step - loss: 0.2054 - accuracy: 0.9219 - val_loss: 0.3672 - val_accuracy: 0.8344\n",
            "Epoch 5/6\n",
            "293/293 [==============================] - 6s 21ms/step - loss: 0.1716 - accuracy: 0.9362 - val_loss: 0.3843 - val_accuracy: 0.8340\n",
            "Epoch 6/6\n",
            "293/293 [==============================] - 5s 17ms/step - loss: 0.1355 - accuracy: 0.9519 - val_loss: 0.4134 - val_accuracy: 0.8294\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faee4641e80>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " model.load_weights('/tmp/checkpoint')\n",
        " model.evaluate(final_test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAtmWh5A1SM5",
        "outputId": "69c34463-f39b-4d0a-b217-5fca73b0642d"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/51 [==============================] - 1s 14ms/step - loss: 0.3785 - accuracy: 0.8400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.378498911857605, 0.8399875164031982]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**With some hyperparameter tuning (changing vocab size, max sequence length and number of trainable parameters), the model achieved an accuracy score of 84% on the test set.**"
      ],
      "metadata": {
        "id": "jEJ5o8oLBpDl"
      }
    }
  ]
}